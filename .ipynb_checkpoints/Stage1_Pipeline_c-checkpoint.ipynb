{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "\n",
    "The tasks to accomplish in this project are as following:\n",
    "\n",
    " 1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    " 2. Apply a distortion correction to raw images.\n",
    " 3. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    " 4. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    " 5. Detect lane pixels and fit to find the lane boundary.\n",
    " 6. Determine the curvature of the lane and vehicle position with respect to center.\n",
    " 7. Warp the detected lane boundaries back onto the original image.\n",
    " 8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Jandal\\\\workspace_P\\\\UNDSC\\\\CarND-Advanced-Lane-Lines'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import os\n",
    "import numpy as np\n",
    "import glob # to read files from dir\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "The solution can be found in <font color=blue>Stage0_Camera_Calibration.ipynb</font> notebook in this directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - 4 steps \n",
    "The solution can be found in <font color=blue>Stage1_Pipeline_a.ipynb</font> notebook in this directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - 8 steps \n",
    "The solution can be found in <font color=blue>Stage1_Pipeline_b.ipynb</font> notebook in this directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook has end to end pipeline executed on test images and sample video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading camera calibration variables from pickle object\n",
    "path_dir = os.getcwd()+\"\\\\pickled_data\\\\\"\n",
    "pickle_obj = pickle.load(open(path_dir+\"camera_calibration.p\", \"rb\" ))\n",
    "mtx = pickle_obj[\"mtx\"]\n",
    "dist = pickle_obj[\"dist\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All helper functions required for pipeline can be found in <font color=blue>pipeline_helper_functions.py</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting helper functions\n",
    "%run pipeline_helper_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Image Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining pipeline function using helper functions\n",
    "def pipeline(original_image):\n",
    "    #1. Undistort, blur and find combined thresholded image\n",
    "    undist_img = undistorted_img(original_image, mtx, dist)\n",
    "    blur_img = cv2.GaussianBlur(undist_img, (9, 9), 0)\n",
    "    combined_img = get_binarized(blur_img)\n",
    "\n",
    "    #2. Get warp perspective of undistorted image\n",
    "    src = np.float32([[400, 600], [980, 600], [815, 500], [550, 500]])\n",
    "    dst = np.float32([[200, 585], [980, 585], [980, 0], [200, 0]])\n",
    "    warped_img = WarpPerspective(combined_img, src, dst) # get perspective transformation\n",
    "    \n",
    "    #3. Get sliding windows\n",
    "    left_fit,right_fit,left_lane_inds,right_lane_inds,out_img = make_sliding_windows(warped_img)\n",
    "    #slidingWindows = visualize_sliding_windows(warped_img,left_fit,right_fit,out_img)\n",
    "    \n",
    "    #4. Get smooth lane pixels, alternative to sliding windows method\n",
    "    margin = 100 # hyper-param\n",
    "    smoothLanes, left_fitx, right_fitx, ploty = get_smooth_lanes(warped_img, margin, left_fit, right_fit)\n",
    "    smoothLanes = cv2.cvtColor(smoothLanes.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    #visualize_smooth_lanes(left_fitx, right_fitx, ploty)\n",
    "    \n",
    "    #5. Unwarp to original image\n",
    "    unwarp_img = unwarp_image(smoothLanes, original_image, src, dst, left_fit, right_fit)\n",
    "    \n",
    "    #6. Print radius of curvature\n",
    "    radius, distance = get_RealRadiusOfCurvature(combined_img, left_fit, right_fit)\n",
    "    cv2.putText(unwarp_img,\"Radius of Curvature = \" + str(int(radius))+ \"m\", (100,100), 2, 1, (255,255,0),2)\n",
    "    cv2.putText(unwarp_img,\"Distance from Center = {:2f}\".format(distance)+ \"m\", (100,150), 2, 1, (255,255,0),2)\n",
    "    \n",
    "    #7. Returning the image with warped_img sticked on it\n",
    "    small_img = np.dstack((smoothLanes*255,smoothLanes*255,smoothLanes*255))\n",
    "    unwarp_img[100:240,1000:1200, :] = cv2.resize(small_img, (200,140))\n",
    "    result_img = unwarp_img.astype(np.uint8)\n",
    "    \n",
    "    return result_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Image Pipeline on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e11a89da75d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Testing on test images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpath_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\\\test_images\\\\\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/*.jpg'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Reading Images from test_images folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Testing on test images\n",
    "f, axes= plt.subplots(8,2,figsize=(15,30))\n",
    "\n",
    "path_dir = os.getcwd()+\"\\\\test_images\\\\\"\n",
    "images = glob.glob(path_dir+'/*.jpg') # Reading Images from test_images folder\n",
    "\n",
    "for index, image in enumerate(images):\n",
    "    img_input = cv2.imread(image)\n",
    "    original_img = cv2.cvtColor(img_input, cv2.COLOR_BGR2RGB)\n",
    "    axes[index,0].imshow(original_img)\n",
    "    result_img = pipeline(original_img)\n",
    "    cv2.imwrite('output_images/test_img'+str(index)+'.jpg', cv2.cvtColor(result_img,cv2.COLOR_BGR2RGB))\n",
    "    axes[index,1].imshow(result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Image Pipeline on sample video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video C:\\Jandal\\workspace_P\\UNDSC\\CarND-Advanced-Lane-Lines\\output_videos\\project_video_output.mp4\n",
      "[MoviePy] Writing video C:\\Jandal\\workspace_P\\UNDSC\\CarND-Advanced-Lane-Lines\\output_videos\\project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████▉| 1260/1261 [08:24<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: C:\\Jandal\\workspace_P\\UNDSC\\CarND-Advanced-Lane-Lines\\output_videos\\project_video_output.mp4 \n",
      "\n",
      "Wall time: 8min 26s\n"
     ]
    }
   ],
   "source": [
    "# Running pipeline() on project_video.mp4\n",
    "import moviepy\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "path_dir = os.getcwd()+\"\\\\output_videos\\\\\"\n",
    "\n",
    "input_projVideo = VideoFileClip('project_video.mp4')\n",
    "video_projVideo = path_dir+'project_video_output.mp4'\n",
    "processed_video = input_projVideo.fl_image(pipeline)\n",
    "%time processed_video.write_videofile(video_projVideo, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video C:\\Jandal\\workspace_P\\UNDSC\\CarND-Advanced-Lane-Lines\\output_videos\\challenge_video_output.mp4\n",
      "[MoviePy] Writing video C:\\Jandal\\workspace_P\\UNDSC\\CarND-Advanced-Lane-Lines\\output_videos\\challenge_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 485/485 [02:30<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: C:\\Jandal\\workspace_P\\UNDSC\\CarND-Advanced-Lane-Lines\\output_videos\\challenge_video_output.mp4 \n",
      "\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "# Running pipeline() on challenge_video.mp4\n",
    "input_challengeVideo = VideoFileClip('challenge_video.mp4')\n",
    "video_challengeVideo = path_dir+'challenge_video_output.mp4'\n",
    "processed_video = input_challengeVideo.fl_image(pipeline)\n",
    "%time processed_video.write_videofile(video_challengeVideo, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video C:\\Jandal\\workspace_P\\UNDSC\\CarND-Advanced-Lane-Lines\\output_videos\\harder_challenge_video_output.mp4\n",
      "[MoviePy] Writing video C:\\Jandal\\workspace_P\\UNDSC\\CarND-Advanced-Lane-Lines\\output_videos\\harder_challenge_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████▉| 1199/1200 [07:21<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: C:\\Jandal\\workspace_P\\UNDSC\\CarND-Advanced-Lane-Lines\\output_videos\\harder_challenge_video_output.mp4 \n",
      "\n",
      "Wall time: 7min 24s\n"
     ]
    }
   ],
   "source": [
    "# Running pipeline() on harder_challenge_video.mp4\n",
    "input_hardChallenge = VideoFileClip('harder_challenge_video.mp4')\n",
    "video_hardChallenge = path_dir+'harder_challenge_video_output.mp4'\n",
    "processed_video = input_hardChallenge.fl_image(pipeline)\n",
    "%time processed_video.write_videofile(video_hardChallenge, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
