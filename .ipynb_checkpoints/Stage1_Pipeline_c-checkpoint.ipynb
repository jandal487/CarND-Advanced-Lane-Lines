{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "\n",
    "The tasks to accomplish in this project are as following:\n",
    "\n",
    " 1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    " 2. Apply a distortion correction to raw images.\n",
    " 3. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    " 4. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    " 5. Detect lane pixels and fit to find the lane boundary.\n",
    " 6. Determine the curvature of the lane and vehicle position with respect to center.\n",
    " 7. Warp the detected lane boundaries back onto the original image.\n",
    " 8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Jandal\\\\workspace_P\\\\UNDSC\\\\CarND-Advanced-Lane-Lines'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import os\n",
    "import numpy as np\n",
    "import glob # to read files from dir\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "The solution can be found in <font color=blue>Stage0_Camera_Calibration.ipynb</font> notebook in this directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - 4 steps \n",
    "The solution can be found in <font color=blue>Stage1_Pipeline_a.ipynb</font> notebook in this directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - 8 steps \n",
    "The solution can be found in <font color=blue>Stage1_Pipeline_b.ipynb</font> notebook in this directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook has end to end pipeline executed on test images and sample video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading camera calibration variables from pickle object\n",
    "path_dir = os.getcwd()+\"\\\\pickled_data\\\\\"\n",
    "pickle_obj = pickle.load(open(path_dir+\"camera_calibration.p\", \"rb\" ))\n",
    "mtx = pickle_obj[\"mtx\"]\n",
    "dist = pickle_obj[\"dist\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All helper functions required for pipeline can be found in <font color=blue>pipeline_helper_functions.py</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting helper functions\n",
    "%run pipeline_helper_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Image Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining pipeline function using helper functions\n",
    "def pipeline(original_image):\n",
    "    #1. Undistort, blur and find combined thresholded image\n",
    "    undist_img = undistorted_img(original_image, mtx, dist)\n",
    "    blur_img = cv2.GaussianBlur(undist_img, (9, 9), 0)\n",
    "    combined_img = get_comb_binarized(blur_img)\n",
    "\n",
    "    #2. Get warp perspective of undistorted image\n",
    "    src = np.float32([[550, 470], [760, 470], [1125, 670], [200, 670]])\n",
    "    #dst = np.float32([[10, 10], [1200, 10], [1200, 700], [10, 700]])\n",
    "    offset = 10\n",
    "    h,w = combined_img.shape\n",
    "    dst = get_dst(offset=offset, w=w, h=h)\n",
    "    warped_img = WarpPerspective(combined_img, src, dst) # get perspective transformation\n",
    "    \n",
    "    #3. Get sliding windows\n",
    "    left_fit,right_fit,left_lane_inds,right_lane_inds,out_img = make_sliding_windows(warped_img)\n",
    "    #slidingWindows = visualize_sliding_windows(warped_img,left_fit,right_fit,out_img)\n",
    "    \n",
    "    #4. Get smooth lane pixels, alternative to sliding windows method\n",
    "    margin = 100 # hyper-param\n",
    "    smoothLanes, left_fitx, right_fitx, ploty = get_smooth_lanes(warped_img, margin, left_fit, right_fit)\n",
    "    smoothLanes = cv2.cvtColor(smoothLanes.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    #visualize_smooth_lanes(left_fitx, right_fitx, ploty)\n",
    "    \n",
    "    #5. Unwarp to original image\n",
    "    unwarp_img = unwarp_image(smoothLanes, original_image, src, dst, left_fit, right_fit)\n",
    "    \n",
    "    #6. Print radius of curvature\n",
    "    radius, distance = get_RealRadiusOfCurvature(combined_img, left_fit, right_fit)\n",
    "    cv2.putText(unwarp_img,\"Radius of Curvature = \" + str(int(radius))+ \"m\", (100,100), 2, 1, (255,255,0),2)\n",
    "    cv2.putText(unwarp_img,\"Distance from Center = {:2f}\".format(distance)+ \"m\", (100,150), 2, 1, (255,255,0),2)\n",
    "    \n",
    "    #7. Returning the image with warped_img sticked on it\n",
    "    small_img1 = np.dstack((combined_img*255,combined_img*255,combined_img*255))\n",
    "    small_img2 = np.dstack((smoothLanes*255,smoothLanes*255,smoothLanes*255))\n",
    "    #unwarp_img[100:240,1000:1200, :] = cv2.resize(small_img, (200,140))\n",
    "    unwarp_img[50:200,1000:1200, :] = cv2.resize(small_img1, (200,140))\n",
    "    unwarp_img[200:350,1000:1200, :] = cv2.resize(small_img2, (200,140))\n",
    "    result_img = unwarp_img.astype(np.uint8)\n",
    "    \n",
    "    return result_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Image Pipeline on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on test images\n",
    "f, axes= plt.subplots(8,2,figsize=(15,30))\n",
    "\n",
    "path_dir = os.getcwd()+\"\\\\test_images\\\\\"\n",
    "images = glob.glob(path_dir+'/*.jpg') # Reading Images from test_images folder\n",
    "\n",
    "for index, image in enumerate(images):\n",
    "    img_input = cv2.imread(image)\n",
    "    original_img = cv2.cvtColor(img_input, cv2.COLOR_BGR2RGB)\n",
    "    axes[index,0].imshow(original_img)\n",
    "    result_img = pipeline(original_img)\n",
    "    #cv2.imwrite('output_images/test_img'+str(index)+'.jpg', cv2.cvtColor(result_img,cv2.COLOR_BGR2RGB))\n",
    "    axes[index,1].imshow(result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Image Pipeline on sample video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video C:\\Jandal\\workspace_P\\UNDSC\\CarND-Advanced-Lane-Lines\\output_videos\\project_video_output.mp4\n",
      "[MoviePy] Writing video C:\\Jandal\\workspace_P\\UNDSC\\CarND-Advanced-Lane-Lines\\output_videos\\project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|█████████████████████████████████▊    | 1121/1261 [06:21<00:47,  2.92it/s]"
     ]
    }
   ],
   "source": [
    "# Running pipeline() on project_video.mp4\n",
    "import moviepy\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "path_dir = os.getcwd()+\"\\\\output_videos\\\\\"\n",
    "\n",
    "input_projVideo = VideoFileClip('project_video.mp4')\n",
    "video_projVideo = path_dir+'project_video_output.mp4'\n",
    "processed_video = input_projVideo.fl_image(pipeline)\n",
    "%time processed_video.write_videofile(video_projVideo, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running pipeline() on challenge_video.mp4\n",
    "input_challengeVideo = VideoFileClip('challenge_video.mp4')\n",
    "video_challengeVideo = path_dir+'challenge_video_output.mp4'\n",
    "processed_video = input_challengeVideo.fl_image(pipeline)\n",
    "%time processed_video.write_videofile(video_challengeVideo, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running pipeline() on harder_challenge_video.mp4\n",
    "input_hardChallenge = VideoFileClip('harder_challenge_video.mp4')\n",
    "video_hardChallenge = path_dir+'harder_challenge_video_output.mp4'\n",
    "processed_video = input_hardChallenge.fl_image(pipeline)\n",
    "%time processed_video.write_videofile(video_hardChallenge, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
